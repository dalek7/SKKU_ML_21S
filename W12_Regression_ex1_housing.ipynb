{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression with Keras (Deep Learning with Keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "Regression is a process where a model learns to predict a continuous value output for a given input data,   \n",
    "  e.g. predict price, length, width, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Definition\n",
    "Our objective is to **build prediction model that predicts housing prices from a set of house features.**  \n",
    "We will use the Boston Housing dataset, which is collected by the U.S Census Service concerning housing in the area of Boston Mass.     \n",
    "The dataset is small in size with only 506 cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It contains 14 features described as follows: \n",
    "* CRIM: per capita crime rate by town\n",
    "* ZN: proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "* INDUS: proportion of non-retail business acres per town.\n",
    "* CHAS: Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n",
    "* NOX: nitric oxides concentration (parts per 10 million)\n",
    "* RM: average number of rooms per dwelling\n",
    "* AGE: proportion of owner-occupied units built prior to 1940\n",
    "* DIS: weighted distances to five Boston employment centres\n",
    "* RAD: index of accessibility to radial highways\n",
    "* TAX: full-value property-tax rate per $10,000  \n",
    "\n",
    "* PTRATIO: pupil-teacher ratio by town\n",
    "* B: 1000(Bk — 0.63)² where Bk is the proportion of blacks by town\n",
    "* LSTAT: % lower status of the population\n",
    "* MEDV: Median value of owner-occupied homes in $1000’s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **The goal behind our regression problem is to use the 13 features to predict the value of MEDV (which represents the housing price).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Keras has a set of datasets already available. You can access them from *keras.dataset*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import boston_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.23247   0.        8.14      0.        0.538     6.142    91.7\n",
      "   3.9769    4.      307.       21.      396.9      18.72   ] 15.2\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()\n",
    "\n",
    "# let us view on sample from the features\n",
    "print(X_train[0], y_train[0])\n",
    "#print(X_test[0], y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is returned as two tuples representing the training and testing splits.  \n",
    "The X_train and X_test contain the feature columns, while the y_train and y_test contain the label/output column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "* Our data needs to be rescaled. Time for our buddy (StandarScaler) from the scikit-learn package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**StandardScaler**  \n",
    "* Change the mean of each feature to 0, and the variance to 1.  \n",
    "* All properties will have the same scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first we fit the scaler on the training dataset\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then we call the transform method to scale both the training and testing data\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.27224633 -0.48361547 -0.43576161 -0.25683275 -0.1652266  -0.1764426\n",
      "  0.81306188  0.1166983  -0.62624905 -0.59517003  1.14850044  0.44807713\n",
      "  0.8252202 ]\n"
     ]
    }
   ],
   "source": [
    "# a sample output\n",
    "print(X_train_scaled[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we only rescale the features and not the label column.  \n",
    "This dataset is simple and no further preprocessing is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model\n",
    "* We will build the model layer by layer in a sequential manner.  \n",
    "To do so we have to **import 1) the model class 2) and the layer class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we create the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we start adding the layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the layers\n",
    "model.add(layers.Dense(8, activation='relu', input_shape=[X_train.shape[1]]))\n",
    "model.add(layers.Dense(16, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we only specify the input shape for the first layer, all layers later will know automatically their input shape from the previous one.  \n",
    "**The activation parameter here specifies the function we want to perform on top of the layer to calculate the output = activation(X * W + bias).**  \n",
    "Relu is a activation function that is used to break the linearity of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output layer\n",
    "model.add(layers.Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output layer is simply a layer with one neuron and linear activation function since we are predicting only one continuous value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 112       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 273\n",
      "Trainable params: 273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the Model\n",
    "* After building the network we need to specify two important things: **1) the optimizer and 2) the loss function.**\n",
    "* The optimizer is responsible for navigating the space to choose the best model parameters, while the loss function is used by the optimizer to know how to move in the search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) optimizer : RMSprop works fine with its default parameters.  \n",
    "\n",
    "2) loss function : Mean Squared Error  \n",
    "    (the average squared error a point is from the mean value)  \n",
    "    \n",
    "3) metrics : Mean Absolute Error  \n",
    "    (Regression Indicators, Absolute value of the difference between the actual value and the measured value,  \n",
    "    In other words, how wrong the model is in prediction.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "* we just have to call the fit method to start training.\n",
    "    * validation_split : the validation split indicates that the model has to keep 20% of the data as a validation set\n",
    "    * epochs : the number of iterations on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 565.0212 - mae: 21.8325 - val_loss: 624.7561 - val_mae: 23.1973\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 549.6344 - mae: 21.5287 - val_loss: 610.9771 - val_mae: 22.9406\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 961us/step - loss: 537.2485 - mae: 21.2825 - val_loss: 597.1677 - val_mae: 22.6825\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 926us/step - loss: 524.7267 - mae: 21.0289 - val_loss: 582.7738 - val_mae: 22.4080\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 943us/step - loss: 511.8459 - mae: 20.7557 - val_loss: 568.0921 - val_mae: 22.1225\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 952us/step - loss: 498.3824 - mae: 20.4734 - val_loss: 551.0344 - val_mae: 21.7893\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 937us/step - loss: 483.5116 - mae: 20.1565 - val_loss: 534.4880 - val_mae: 21.4570\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 916us/step - loss: 468.3332 - mae: 19.8273 - val_loss: 515.2676 - val_mae: 21.0695\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 935us/step - loss: 451.6445 - mae: 19.4600 - val_loss: 497.1780 - val_mae: 20.6872\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 936us/step - loss: 434.9601 - mae: 19.0782 - val_loss: 478.7069 - val_mae: 20.2868\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 939us/step - loss: 417.8375 - mae: 18.6792 - val_loss: 457.8913 - val_mae: 19.8248\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 960us/step - loss: 398.8334 - mae: 18.2223 - val_loss: 436.8135 - val_mae: 19.3429\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 958us/step - loss: 379.2896 - mae: 17.7402 - val_loss: 414.4761 - val_mae: 18.8125\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 954us/step - loss: 358.2952 - mae: 17.2154 - val_loss: 391.2060 - val_mae: 18.2414\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 996us/step - loss: 336.7413 - mae: 16.6442 - val_loss: 368.7086 - val_mae: 17.6657\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 953us/step - loss: 314.9887 - mae: 16.0587 - val_loss: 342.9438 - val_mae: 16.9856\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 966us/step - loss: 291.5409 - mae: 15.4043 - val_loss: 317.7768 - val_mae: 16.2839\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 980us/step - loss: 268.2885 - mae: 14.7023 - val_loss: 291.6064 - val_mae: 15.5215\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 243.8774 - mae: 13.9631 - val_loss: 267.0179 - val_mae: 14.7583\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 955us/step - loss: 220.8585 - mae: 13.2063 - val_loss: 240.9828 - val_mae: 13.9052\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 978us/step - loss: 197.3253 - mae: 12.3930 - val_loss: 217.6290 - val_mae: 13.0768\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 947us/step - loss: 175.2441 - mae: 11.5739 - val_loss: 192.8208 - val_mae: 12.1268\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 951us/step - loss: 152.8587 - mae: 10.6724 - val_loss: 169.0333 - val_mae: 11.1371\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 924us/step - loss: 131.5858 - mae: 9.7335 - val_loss: 146.8672 - val_mae: 10.1254\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 941us/step - loss: 112.2475 - mae: 8.7964 - val_loss: 128.0352 - val_mae: 9.1410\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 942us/step - loss: 95.4720 - mae: 7.8704 - val_loss: 110.3518 - val_mae: 8.0839\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 956us/step - loss: 80.6051 - mae: 6.9455 - val_loss: 95.2931 - val_mae: 7.1054\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 955us/step - loss: 68.1598 - mae: 6.0762 - val_loss: 81.5071 - val_mae: 6.3227\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 989us/step - loss: 58.1753 - mae: 5.3647 - val_loss: 73.5672 - val_mae: 5.8813\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 990us/step - loss: 52.1606 - mae: 4.9715 - val_loss: 67.2567 - val_mae: 5.5191\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 47.7853 - mae: 4.7312 - val_loss: 61.1975 - val_mae: 5.1883\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 996us/step - loss: 44.3639 - mae: 4.5535 - val_loss: 57.9728 - val_mae: 5.0829\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 42.6638 - mae: 4.4758 - val_loss: 55.6158 - val_mae: 4.9822\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 968us/step - loss: 41.3792 - mae: 4.3911 - val_loss: 52.6567 - val_mae: 4.8330\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 948us/step - loss: 40.0608 - mae: 4.3093 - val_loss: 49.8910 - val_mae: 4.7186\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 994us/step - loss: 38.8390 - mae: 4.2341 - val_loss: 47.3579 - val_mae: 4.6101\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 979us/step - loss: 37.8263 - mae: 4.1713 - val_loss: 45.6748 - val_mae: 4.5094\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 36.9707 - mae: 4.1011 - val_loss: 44.4151 - val_mae: 4.4567\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 36.2300 - mae: 4.0535 - val_loss: 42.6599 - val_mae: 4.3574\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 35.4887 - mae: 4.0106 - val_loss: 41.0919 - val_mae: 4.2968\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 34.8142 - mae: 3.9737 - val_loss: 39.7874 - val_mae: 4.2347\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 34.1327 - mae: 3.9457 - val_loss: 39.1078 - val_mae: 4.1901\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 33.6487 - mae: 3.8971 - val_loss: 38.0094 - val_mae: 4.1309\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 32.8855 - mae: 3.8525 - val_loss: 37.1202 - val_mae: 4.0645\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 32.3001 - mae: 3.8098 - val_loss: 35.9623 - val_mae: 4.0167\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 973us/step - loss: 31.7303 - mae: 3.7787 - val_loss: 35.0277 - val_mae: 3.9542\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 985us/step - loss: 31.1261 - mae: 3.7356 - val_loss: 34.2283 - val_mae: 3.8987\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 30.5492 - mae: 3.6754 - val_loss: 33.4763 - val_mae: 3.8691\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 30.1584 - mae: 3.6667 - val_loss: 32.5771 - val_mae: 3.8045\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 29.6076 - mae: 3.6260 - val_loss: 31.7950 - val_mae: 3.7615\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 29.1911 - mae: 3.5989 - val_loss: 31.0245 - val_mae: 3.7178\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 28.7387 - mae: 3.5602 - val_loss: 29.9421 - val_mae: 3.6704\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 988us/step - loss: 28.1550 - mae: 3.5418 - val_loss: 29.2819 - val_mae: 3.6319\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 991us/step - loss: 27.7318 - mae: 3.5225 - val_loss: 28.8827 - val_mae: 3.6092\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 996us/step - loss: 27.4132 - mae: 3.4759 - val_loss: 28.1600 - val_mae: 3.6142\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 26.8801 - mae: 3.4738 - val_loss: 27.5740 - val_mae: 3.5443\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 26.4192 - mae: 3.4047 - val_loss: 26.7179 - val_mae: 3.5194\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 26.1435 - mae: 3.4175 - val_loss: 25.9119 - val_mae: 3.4535\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 25.7047 - mae: 3.3704 - val_loss: 25.5200 - val_mae: 3.4337\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 25.3177 - mae: 3.3398 - val_loss: 24.9358 - val_mae: 3.4094\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 24.9953 - mae: 3.3164 - val_loss: 24.7828 - val_mae: 3.3974\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 24.5269 - mae: 3.2927 - val_loss: 23.8711 - val_mae: 3.3282\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 24.1083 - mae: 3.2644 - val_loss: 22.9581 - val_mae: 3.2751\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 23.7683 - mae: 3.2561 - val_loss: 22.2403 - val_mae: 3.2319\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 23.2993 - mae: 3.2208 - val_loss: 21.7330 - val_mae: 3.2058\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 965us/step - loss: 22.8429 - mae: 3.1882 - val_loss: 21.2555 - val_mae: 3.1916\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 22.4280 - mae: 3.1742 - val_loss: 20.9150 - val_mae: 3.1837\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 22.1172 - mae: 3.1418 - val_loss: 20.5587 - val_mae: 3.1638\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 998us/step - loss: 21.8396 - mae: 3.1061 - val_loss: 20.2654 - val_mae: 3.1566\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 994us/step - loss: 21.5376 - mae: 3.0826 - val_loss: 19.5082 - val_mae: 3.0926\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 21.1251 - mae: 3.0518 - val_loss: 18.9616 - val_mae: 3.0633\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 973us/step - loss: 20.8872 - mae: 3.0315 - val_loss: 18.3190 - val_mae: 3.0176\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 987us/step - loss: 20.5578 - mae: 3.0183 - val_loss: 17.7669 - val_mae: 2.9862\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 999us/step - loss: 20.1483 - mae: 2.9902 - val_loss: 17.7305 - val_mae: 3.0053\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 992us/step - loss: 19.8731 - mae: 2.9620 - val_loss: 17.3019 - val_mae: 2.9694\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 985us/step - loss: 19.5380 - mae: 2.9640 - val_loss: 16.7995 - val_mae: 2.9274\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 994us/step - loss: 19.2199 - mae: 2.9331 - val_loss: 16.3303 - val_mae: 2.9029\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 18.8891 - mae: 2.9005 - val_loss: 15.9824 - val_mae: 2.8792\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 18.6176 - mae: 2.8828 - val_loss: 15.5442 - val_mae: 2.8505\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 18.3738 - mae: 2.8681 - val_loss: 15.3094 - val_mae: 2.8436\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 18.1079 - mae: 2.8373 - val_loss: 14.5635 - val_mae: 2.7663\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 981us/step - loss: 17.8436 - mae: 2.8297 - val_loss: 14.4460 - val_mae: 2.7739\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 984us/step - loss: 17.5302 - mae: 2.8165 - val_loss: 14.5519 - val_mae: 2.8054\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 17.3518 - mae: 2.8004 - val_loss: 13.9680 - val_mae: 2.7516\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 17.1440 - mae: 2.7905 - val_loss: 13.7163 - val_mae: 2.7400\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 952us/step - loss: 16.8275 - mae: 2.7623 - val_loss: 13.8290 - val_mae: 2.7654\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 948us/step - loss: 16.7010 - mae: 2.7675 - val_loss: 13.0858 - val_mae: 2.6949\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 986us/step - loss: 16.4300 - mae: 2.7390 - val_loss: 12.7272 - val_mae: 2.6758\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 984us/step - loss: 16.1862 - mae: 2.7204 - val_loss: 12.6253 - val_mae: 2.6904\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 953us/step - loss: 15.9987 - mae: 2.7191 - val_loss: 12.0668 - val_mae: 2.6437\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 938us/step - loss: 15.7762 - mae: 2.7044 - val_loss: 11.9899 - val_mae: 2.6497\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 967us/step - loss: 15.6575 - mae: 2.7056 - val_loss: 12.0148 - val_mae: 2.6557\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 955us/step - loss: 15.4739 - mae: 2.6693 - val_loss: 11.7659 - val_mae: 2.6431\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 986us/step - loss: 15.3086 - mae: 2.6808 - val_loss: 11.5369 - val_mae: 2.6177\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 978us/step - loss: 15.1892 - mae: 2.6666 - val_loss: 11.3716 - val_mae: 2.6085\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 975us/step - loss: 15.0444 - mae: 2.6366 - val_loss: 11.4617 - val_mae: 2.6127\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 983us/step - loss: 14.8818 - mae: 2.6216 - val_loss: 11.7198 - val_mae: 2.6510\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 968us/step - loss: 14.8689 - mae: 2.6322 - val_loss: 10.9386 - val_mae: 2.5654\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 989us/step - loss: 14.6441 - mae: 2.6006 - val_loss: 10.8865 - val_mae: 2.5647\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 998us/step - loss: 14.5645 - mae: 2.5977 - val_loss: 10.8011 - val_mae: 2.5702\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, validation_split=0.2, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let us plot the training and validation error convergence according to the epoch number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "training_error = history.history['mae'] # training error\n",
    "val_error = history.history['val_mae'] # validation error\n",
    "\n",
    "plt.plot(training_error)\n",
    "plt.plot(val_error)\n",
    "plt.title('training and validation error')\n",
    "plt.legend(['Training Error', 'Validation Error'], loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We started with an error of 20K per prediction, and went down to around 3K.  \n",
    "This is a very acceptable error value for a housing price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on Test Data\n",
    "* Model evaluation is super easy in Keras. Check the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 391us/step - loss: 22.6691 - mae: 3.2405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[22.669069290161133, 3.240532636642456]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output values represent the loss (Mean Squarred Error) and the metrics (Mean Absolute Error)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prediction\n",
    "* Using the model for prediction is simpler than you expect. Have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16.16263 ]\n",
      " [40.133457]]\n",
      "-------------\n",
      "[15.2 42.3]\n"
     ]
    }
   ],
   "source": [
    "# we get a sample data (the first 2 inputs from the training data)\n",
    "to_predict = X_train_scaled[:2]\n",
    "#print(to_predict)\n",
    "\n",
    "# we call the predict method\n",
    "predictions = model.predict(to_predict)\n",
    "\n",
    "# print the predictions\n",
    "print(predictions)\n",
    "\n",
    "# print the real values\n",
    "print(\"-------------\")\n",
    "print(y_train[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* References  \n",
    "    - Regression with Keras (Deep Learning with Keras – Part 3)  \n",
    "    https://www.marktechpost.com/2019/06/17/regression-with-keras-deep-learning-with-keras-part-3/\n",
    "    - StandardScaler  \n",
    "    https://homeproject.tistory.com/entry/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%8A%A4%EC%BC%80%EC%9D%BC%EB%A7%81-Data-Scaling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
